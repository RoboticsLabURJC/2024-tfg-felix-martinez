---
title: "Semana 11 y 12 - Primer Entrenamiento del modelo PointNet"
categories:
  - Weblog
tags:
  - Python
  - Segmentación
  - PointNet
  - Tensorflow
  - Keras
---

Estas semanas me he dedicado a investigar el funcionamiento de la arquitectura **PointNet** para la segmentación semántica en nubes de puntos. También preparé un pequeño conjunto de entrenamiento para probar la implementación que hice en Tensorflow (Keras) de esta. He utilizado 150 muestras del dataset GOOSE para optimizar el tiempo de computación y comprobar su funcionamiento, sin esperar grandes resultados.

---

### Arquitectura *PointNet*

**PointNet** es una arquitectura de red neuronal diseñada para procesar directamente nubes de puntos en 3D, una representación común en tareas como clasificación, segmentación y estimación de poses en visión por computadora. Su diseño aborda el desafío de trabajar con datos no estructurados y desordenados, características intrínsecas de las nubes de puntos.

#### 1. **Alineación de los puntos**
- Aprende a "ordenar" los puntos usando una pequeña red que calcula una transformación espacial (matriz).
- Esto asegura que la red sea invariante a rotaciones y traslaciones de la nube.

#### 2. **Extracción de características por punto**
- Cada punto de la nube pasa por un MLP (Perceptrón Multicapa) compartido, que transforma las coordenadas del punto en características útiles.
- Cada punto se procesa de forma independiente.

#### 3. **Resumen global de la nube**
- Usa una función de *pooling* simétrica (como *max-pooling*) para resumir las características de todos los puntos en un único vector global.
- Esto garantiza que el resultado sea invariante al orden de los puntos.

#### 4. **Clasificación o segmentación**
- **Clasificación**: Usa el vector global para predecir una etiqueta única para la nube completa.
- **Segmentación**: Combina el vector global con las características individuales de los puntos para asignar una etiqueta a cada punto.

---

### Implementación del Modelo en Keras

<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/pointnet_model.h5.png" alt="Visor 3D">
</figure>

#### Código

```python
# Dividimos en entrenamiento y validación
from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(points, labels, test_size=0.2, random_state=42)

# -----------------------------
# DEFINICIÓN DEL MODELO POINTNET
# -----------------------------
def build_pointnet(num_classes, input_dim=4):
    """
    Modelo PointNet para clasificación punto a punto.
    """
    inputs = tf.keras.Input(shape=(None, input_dim))  # Entrada: N puntos con D características

    # MLP Layers
    x = layers.Conv1D(64, 1, activation='relu')(inputs)
    x = layers.Conv1D(128, 1, activation='relu')(x)
    x = layers.Conv1D(1024, 1, activation='relu')(x)

    # Global Feature Aggregation
    global_features = layers.GlobalMaxPooling1D()(x)
    global_features = layers.RepeatVector(MAX_POINTS)(global_features)  # Repetir para cada punto
    global_features = layers.Conv1D(1024, 1, activation='relu')(global_features)

    # Concatenar características globales y locales
    x = layers.concatenate([x, global_features])

    # MLP final para clasificación
    x = layers.Conv1D(512, 1, activation='relu')(x)
    x = layers.Conv1D(256, 1, activation='relu')(x)
    outputs = layers.Conv1D(num_classes, 1, activation='softmax')(x)  # Clasificación por punto

    return tf.keras.Model(inputs, outputs)

# Construir y compilar el modelo
pointnet_model = build_pointnet(num_classes=64, input_dim=4)
pointnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Resumen del modelo
pointnet_model.summary()

# -----------------------------
# ENTRENAMIENTO DEL MODELO
# -----------------------------
history = pointnet_model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=10,  # Ajustar según los recursos
    batch_size=8,  # Ajustar según la memoria disponible
    verbose=1
)

# -----------------------------
# EVALUACIÓN
# -----------------------------
loss, accuracy = pointnet_model.evaluate(x_val, y_val)
print(f"Loss: {loss}, Accuracy: {accuracy}")

# -----------------------------
# PREDICCIONES
# -----------------------------
# Predicciones punto a punto
predictions = pointnet_model.predict(x_val)
predicted_labels = np.argmax(predictions, axis=-1)  # Etiquetas por punto
print("Predicciones para la primera nube:", predicted_labels[0])
print("Etiquetas reales para la primera nube:", y_val[0])
```

### Resultados

Los resultados en segmentación no son buenos por el tamaño reducido del conjunto de datos, sin embargo **prueban el funcionamiento de la arquitectura**. Hay que tener en cuenta que no buscaba obtener una precisión y exactitud elevadas en los resultados, solo probar la implementación sin sobrecargar computacionalmente el proceso.

<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/metrics1.png" alt="Visor 3D">
</figure>

<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/metrics2.png" alt="Visor 3D">
</figure>

Los resultados muestran como se reduce la pérdida (_loss_) y aumenta la precisión (_precision_) durante las 10 épocas (_epochs_) del entrenamiento. Esto demuestra que el modelo es funcional y tiene potencial para segmentar correctamente una vez se aumente el conjunto de datos de entrenamiento.

### Normalización de los datos de entrada

Es importante destacar que todas las **características** que describen cada punto, **deben estar normalizadas** para que la ***RNA*** se comporte adecuadamente en el prodeso de entrenamiento.