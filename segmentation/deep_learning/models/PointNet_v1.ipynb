{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Implementación del modelo PointNet para segmentación de nubes de puntos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Importaciones*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Carga del Rutas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una ventana oculta de Tkinter\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Create a hidden Tkinter window\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "\n",
    "# Initial path\n",
    "initial_path = Path(r'C:\\Users\\fmartinez\\Desktop\\reco\\datasets_slipt')\n",
    "\n",
    "try:\n",
    "    # Select the first path\n",
    "    print(\"Select the path for 'x_train'\")\n",
    "    x_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the second path\n",
    "    print(\"Select the path for 'y_train'\")\n",
    "    y_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the third path\n",
    "    print(\"Select the path for 'x_val'\")\n",
    "    x_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the fourth path\n",
    "    print(\"Select the path for 'y_val'\")\n",
    "    y_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Show the selected paths\n",
    "    print(f\"Path selected for x_train: {x_train_path}\")\n",
    "    print(f\"Path selected for y_train: {y_train_path}\")\n",
    "    print(f\"Path selected for x_val: {x_val_path}\")\n",
    "    print(f\"Path selected for y_val: {y_val_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error selecting paths: {e}\")\n",
    "\n",
    "finally:\n",
    "    root.destroy()  # Ensure the Tkinter window is closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Carga de Datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(x_path, y_path):\n",
    "    X_data, Y_data = [], []\n",
    "\n",
    "    for x_file in Path(x_path).iterdir():\n",
    "        if x_file.is_file() and x_file.suffix == '.csv':\n",
    "            y_file = Path(y_path) / x_file.name.replace('x_', 'y_')\n",
    "\n",
    "            # Load x and y\n",
    "            x_df = pd.read_csv(x_file, header=None, skiprows=1)  # Omitir la primera fila si es encabezado\n",
    "            y_df = pd.read_csv(y_file, header=None, skiprows=1)  # Omitir la primera fila si es encabezado\n",
    "\n",
    "            try:\n",
    "                # Convert to float and select x, y, z features\n",
    "                x_features = x_df.iloc[:, [0, 1, 2]].astype(float).values\n",
    "                labels = y_df.iloc[:, 0].values\n",
    "\n",
    "                X_data.append(x_features)\n",
    "                Y_data.append(labels)\n",
    "            except ValueError:\n",
    "                print(f\"Error en el archivo: {x_file}, revisa que los datos sean numéricos.\")\n",
    "\n",
    "    return X_data, Y_data\n",
    "\n",
    "# Load training and validation data\n",
    "x_train, y_train = load_data(x_train_path, y_train_path)\n",
    "x_val, y_val = load_data(x_val_path, y_val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 64\n",
    "\n",
    "# Calculate class weights\n",
    "def calculate_class_weights(y_data):\n",
    "    all_labels = np.concatenate(y_data)\n",
    "    class_counts = np.bincount(all_labels, minlength=num_classes)\n",
    "    total_samples = len(all_labels)\n",
    "    class_weights = {i: total_samples / (num_classes * count) for i, count in enumerate(class_counts) if count > 0}\n",
    "    return class_weights\n",
    "\n",
    "class_weights = calculate_class_weights(y_train)\n",
    "print(f\"Calculated class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacion de PointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se define el bloque T-Net para el ajuste espacial mediante una matriz de transformación que aprende. De esta manera el modelo es robusto a las posibles rotaciones que los objetos puedan tener en el espacio. Se utilizan capas convolucionales 1D que funcionan como MPL pero aunemtan la eficiencia computacional del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom layer for dynamic tiling of global features\n",
    "class DynamicTileGlobalFeature(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        global_feature, input_tensor = inputs\n",
    "        num_points = tf.shape(input_tensor)[1]  # Get the number of points dynamically\n",
    "        global_feature = tf.expand_dims(global_feature, axis=1)  # Add a dimension\n",
    "        global_feature = tf.tile(global_feature, [1, num_points, 1])  # Repeat to match input points\n",
    "        return global_feature\n",
    "\n",
    "# Define PointNet model\n",
    "def tnet(inputs, k):\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(inputs)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(1024, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Output transformation matrix\n",
    "    x = layers.Dense(k * k, \n",
    "                    kernel_initializer=tf.keras.initializers.Zeros(), \n",
    "                    bias_initializer=tf.keras.initializers.Constant(np.eye(k).flatten()))(x)\n",
    "    return layers.Reshape((k, k))(x)\n",
    "\n",
    "def pointnet_segmentation(num_points, num_classes):\n",
    "    inputs = layers.Input(shape=(None, 3))  # Input shape (N, 3)\n",
    "\n",
    "    tnet_input = tnet(inputs, 3)\n",
    "    transformed_inputs = layers.Dot(axes=(2, 1))([inputs, tnet_input])\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(transformed_inputs)\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(x)\n",
    "\n",
    "    tnet_feature = tnet(x, 64)\n",
    "    transformed_features = layers.Dot(axes=(2, 1))([x, tnet_feature])\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(transformed_features)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(1024, kernel_size=1, activation='relu')(x)\n",
    "\n",
    "    global_feature = layers.GlobalMaxPooling1D()(x)\n",
    "    global_feature = DynamicTileGlobalFeature()([global_feature, inputs])  # Use the custom layer\n",
    "\n",
    "    # Segmentation MLP\n",
    "    concat_features = layers.Concatenate()([transformed_features, global_feature])\n",
    "    x = layers.Conv1D(512, kernel_size=1, activation='relu')(concat_features)\n",
    "    x = layers.Conv1D(256, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 64\n",
    "model = pointnet_segmentation(num_points=None, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model with custom metrics\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'mae', tf.keras.metrics.Precision(name='precision')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "# Train the model with the callback\n",
    "history = model.fit(\n",
    "    steps_per_epoch=len(x_train) // batch_size,\n",
    "    validation_steps=len(x_val) // batch_size,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "# Plot training progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_progress(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_progress(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
