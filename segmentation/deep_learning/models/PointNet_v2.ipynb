{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:09:45.416411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738318185.433718   12872 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738318185.438395   12872 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 11:09:45.454996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos disponibles: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Dispositivos disponibles después de forzar CPU: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:09:48.948381: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-01-31 11:09:48.948425: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: pc1\n",
      "2025-01-31 11:09:48.948436: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: pc1\n",
      "2025-01-31 11:09:48.948558: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 550.120.0\n",
      "2025-01-31 11:09:48.948594: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 550.120.0\n",
      "2025-01-31 11:09:48.948603: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 550.120.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Verificar si realmente estamos en CPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Advertencia: ¡Todavía hay una GPU activa!\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles después de forzar CPU:\", tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the path for 'x_train'\n",
      "Select the path for 'y_train'\n",
      "Select the path for 'x_val'\n",
      "Select the path for 'y_val'\n",
      "Path selected for x_train: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/x_train\n",
      "Path selected for y_train: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/y_train\n",
      "Path selected for x_val: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/x_val\n",
      "Path selected for y_val: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/y_val\n"
     ]
    }
   ],
   "source": [
    "# Crear una ventana oculta de Tkinter\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Create a hidden Tkinter window\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "\n",
    "# Initial path\n",
    "initial_path = Path(r'/home/felix/Escritorio/TFG/datasets_norm/goose_norm_test')\n",
    "\n",
    "\n",
    "try:\n",
    "    # Select the first path\n",
    "    print(\"Select the path for 'x_train'\")\n",
    "    x_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the second path\n",
    "    print(\"Select the path for 'y_train'\")\n",
    "    y_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the third path\n",
    "    print(\"Select the path for 'x_val'\")\n",
    "    x_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the fourth path\n",
    "    print(\"Select the path for 'y_val'\")\n",
    "    y_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Show the selected paths\n",
    "    print(f\"Path selected for x_train: {x_train_path}\")\n",
    "    print(f\"Path selected for y_train: {y_train_path}\")\n",
    "    print(f\"Path selected for x_val: {x_val_path}\")\n",
    "    print(f\"Path selected for y_val: {y_val_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error selecting paths: {e}\")\n",
    "\n",
    "finally:\n",
    "    root.destroy()  # Ensure the Tkinter window is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar y procesar los datos\n",
    "def load_data(x_path, y_path):\n",
    "    X_data, Y_data = [], []\n",
    "    num_points_list = []\n",
    "\n",
    "    for x_file in Path(x_path).iterdir():\n",
    "        if x_file.is_file() and x_file.suffix == '.csv':\n",
    "            y_file = Path(y_path) / x_file.name.replace('x_', 'y_')\n",
    "\n",
    "            x_df = pd.read_csv(x_file, header=None, skiprows=1)\n",
    "            y_df = pd.read_csv(y_file, header=None, skiprows=1)\n",
    "\n",
    "            x_features = x_df.iloc[:, [0, 1, 2]].astype(float).values\n",
    "            labels = y_df.iloc[:, 0].values\n",
    "\n",
    "            X_data.append(x_features)\n",
    "            Y_data.append(labels)\n",
    "            num_points_list.append(len(x_features))\n",
    "    \n",
    "    return X_data, Y_data, min(num_points_list)  # Retorna además el número mínimo de puntos\n",
    "\n",
    "# Cargar datos y obtener la cantidad mínima de puntos\n",
    "x_train, y_train, min_train_points = load_data(x_train_path, y_train_path)\n",
    "x_val, y_val, min_val_points = load_data(x_val_path, y_val_path)\n",
    "\n",
    "min_points = min(min_train_points, min_val_points)  # Definir la cantidad mínima global\n",
    "\n",
    "def downsample_data(X_data, Y_data, num_points):\n",
    "    X_downsampled, Y_downsampled = [], []\n",
    "    for x, y in zip(X_data, Y_data):\n",
    "        indices = np.random.permutation(len(x))[:num_points]  # Selección aleatoria\n",
    "        X_downsampled.append(x[indices])\n",
    "        Y_downsampled.append(y[indices])\n",
    "    return np.array(X_downsampled), np.array(Y_downsampled)\n",
    "\n",
    "# Aplicar el downsampling\n",
    "x_train, y_train = downsample_data(x_train, y_train, min_points)\n",
    "x_val, y_val = downsample_data(x_val, y_val, min_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (525, 119809, 3), y_train shape: (525, 119809)\n",
      "x_val shape: (132, 119809, 3), y_val shape: (132, 119809)\n"
     ]
    }
   ],
   "source": [
    "# Verificar las formas de los datos\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-Net para transformación de entrada\n",
    "def tnet(inputs, k):\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(1024, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(k * k, kernel_initializer=tf.keras.initializers.GlorotUniform())(x)\n",
    "    return layers.Reshape((k, k))(x)\n",
    "\n",
    "# Modelo PointNet mejorado\n",
    "def pointnet_segmentation(num_points, num_classes):\n",
    "    inputs = layers.Input(shape=(num_points, 3))\n",
    "\n",
    "    tnet_input = tnet(inputs, 3)\n",
    "    transformed_inputs = layers.Dot(axes=(2, 1))([inputs, tnet_input])\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(transformed_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    tnet_feature = tnet(x, 64)\n",
    "    transformed_features = layers.Dot(axes=(2, 1))([x, tnet_feature])\n",
    "\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(transformed_features)\n",
    "    x = layers.Conv1D(1024, kernel_size=1, activation='relu')(x)\n",
    "    global_feature = layers.GlobalMaxPooling1D()(x)\n",
    "    global_feature = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(global_feature)\n",
    "    global_feature = layers.Lambda(lambda x: tf.tile(x, [1, num_points, 1]))(global_feature)\n",
    "\n",
    "    x = layers.Concatenate()([transformed_features, global_feature])\n",
    "    x = layers.Conv1D(512, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(256, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpointnet_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m      4\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m               )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mpointnet_segmentation\u001b[0;34m(num_points, num_classes)\u001b[0m\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv1D(\u001b[38;5;241m1024\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m     31\u001b[0m global_feature \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mGlobalMaxPooling1D()(x)\n\u001b[0;32m---> 32\u001b[0m global_feature \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m global_feature \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtile(global_feature, [\u001b[38;5;241m1\u001b[39m, num_points, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConcatenate()([transformed_features, global_feature])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:138\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "num_classes = 64\n",
    "model = pointnet_segmentation(min_points, num_classes)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
