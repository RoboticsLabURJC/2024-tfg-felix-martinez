{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:09:45.416411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738318185.433718   12872 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738318185.438395   12872 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 11:09:45.454996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos disponibles: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Dispositivos disponibles después de forzar CPU: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:09:48.948381: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-01-31 11:09:48.948425: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: pc1\n",
      "2025-01-31 11:09:48.948436: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: pc1\n",
      "2025-01-31 11:09:48.948558: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 550.120.0\n",
      "2025-01-31 11:09:48.948594: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 550.120.0\n",
      "2025-01-31 11:09:48.948603: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 550.120.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Verificar si realmente estamos en CPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Advertencia: ¡Todavía hay una GPU activa!\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles después de forzar CPU:\", tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the path for 'x_train'\n",
      "Select the path for 'y_train'\n",
      "Select the path for 'x_val'\n",
      "Select the path for 'y_val'\n",
      "Path selected for x_train: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/x_train\n",
      "Path selected for y_train: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/y_train\n",
      "Path selected for x_val: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/x_val\n",
      "Path selected for y_val: /home/felix/Escritorio/TFG/datasets_norm/goose_norm_test/y_val\n"
     ]
    }
   ],
   "source": [
    "# Crear una ventana oculta de Tkinter\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Create a hidden Tkinter window\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "\n",
    "# Initial path\n",
    "initial_path = Path(r'/home/felix/Escritorio/TFG/datasets_norm/goose_norm_test')\n",
    "\n",
    "\n",
    "try:\n",
    "    # Select the first path\n",
    "    print(\"Select the path for 'x_train'\")\n",
    "    x_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the second path\n",
    "    print(\"Select the path for 'y_train'\")\n",
    "    y_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the third path\n",
    "    print(\"Select the path for 'x_val'\")\n",
    "    x_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the fourth path\n",
    "    print(\"Select the path for 'y_val'\")\n",
    "    y_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Show the selected paths\n",
    "    print(f\"Path selected for x_train: {x_train_path}\")\n",
    "    print(f\"Path selected for y_train: {y_train_path}\")\n",
    "    print(f\"Path selected for x_val: {x_val_path}\")\n",
    "    print(f\"Path selected for y_val: {y_val_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error selecting paths: {e}\")\n",
    "\n",
    "finally:\n",
    "    root.destroy()  # Ensure the Tkinter window is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar y procesar los datos\n",
    "def load_data(x_path, y_path):\n",
    "    X_data, Y_data = [], []\n",
    "    num_points_list = []\n",
    "\n",
    "    for x_file in Path(x_path).iterdir():\n",
    "        if x_file.is_file() and x_file.suffix == '.csv':\n",
    "            y_file = Path(y_path) / x_file.name.replace('x_', 'y_')\n",
    "\n",
    "            x_df = pd.read_csv(x_file, header=None, skiprows=1)\n",
    "            y_df = pd.read_csv(y_file, header=None, skiprows=1)\n",
    "\n",
    "            x_features = x_df.iloc[:, [0, 1, 2]].astype(float).values\n",
    "            labels = y_df.iloc[:, 0].values\n",
    "\n",
    "            X_data.append(x_features)\n",
    "            Y_data.append(labels)\n",
    "            num_points_list.append(len(x_features))\n",
    "    \n",
    "    return X_data, Y_data, min(num_points_list)  # Retorna además el número mínimo de puntos\n",
    "\n",
    "# Cargar datos y obtener la cantidad mínima de puntos\n",
    "x_train, y_train, min_train_points = load_data(x_train_path, y_train_path)\n",
    "x_val, y_val, min_val_points = load_data(x_val_path, y_val_path)\n",
    "\n",
    "min_points = min(min_train_points, min_val_points)  # Definir la cantidad mínima global\n",
    "\n",
    "# def downsample_data(X_data, Y_data, num_points):\n",
    "#    X_downsampled, Y_downsampled = [], []\n",
    "#    for x, y in zip(X_data, Y_data):\n",
    "#        indices = np.random.permutation(len(x))[:num_points]  # Selección aleatoria\n",
    "#       X_downsampled.append(x[indices])\n",
    "#        Y_downsampled.append(y[indices])\n",
    "#    return np.array(X_downsampled), np.array(Y_downsampled)\n",
    "\n",
    "# Aplicar el downsampling\n",
    "#x_train, y_train = downsample_data(x_train, y_train, min_points)\n",
    "\n",
    "#x_val, y_val = downsample_data(x_val, y_val, min_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (525, 119809, 3), y_train shape: (525, 119809)\n",
      "x_val shape: (132, 119809, 3), y_val shape: (132, 119809)\n"
     ]
    }
   ],
   "source": [
    "# Verificar las formas de los datos\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-Net para transformación de entrada\n",
    "def tnet(inputs, k):\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(1024, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(k * k, kernel_initializer=tf.keras.initializers.GlorotUniform())(x)\n",
    "    return layers.Reshape((k, k))(x)\n",
    "\n",
    "# Modelo PointNet mejorado\n",
    "def pointnet_segmentation(num_points, num_classes):\n",
    "    inputs = layers.Input(shape=(num_points, 3))\n",
    "\n",
    "    tnet_input = tnet(inputs, 3)\n",
    "    transformed_inputs = layers.Dot(axes=(2, 1))([inputs, tnet_input])\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(transformed_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    tnet_feature = tnet(x, 64)\n",
    "    transformed_features = layers.Dot(axes=(2, 1))([x, tnet_feature])\n",
    "\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(transformed_features)\n",
    "    x = layers.Conv1D(1024, kernel_size=1, activation='relu')(x)\n",
    "    global_feature = layers.GlobalMaxPooling1D()(x)\n",
    "    global_feature = layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(global_feature)\n",
    "    global_feature = layers.Lambda(lambda x: tf.tile(x, [1, num_points, 1]))(global_feature)\n",
    "\n",
    "    x = layers.Concatenate()([transformed_features, global_feature])\n",
    "    x = layers.Conv1D(512, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(256, kernel_size=1, activation='relu')(x)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 64\n",
    "model = pointnet_segmentation(min_points, num_classes)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "                  tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:15:30.027581: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 754796700 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 11:15:30.761655: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 503197800 exceeds 10% of free system memory.\n",
      "2025-01-31 11:15:36.471770: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 490737664 exceeds 10% of free system memory.\n",
      "2025-01-31 11:15:36.767193: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 490737664 exceeds 10% of free system memory.\n",
      "2025-01-31 11:15:36.940026: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 490737664 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
