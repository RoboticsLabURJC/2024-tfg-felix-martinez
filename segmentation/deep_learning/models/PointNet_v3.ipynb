{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 19:43:29.929379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739213010.141132    7153 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739213010.201756    7153 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 19:43:30.626199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos disponibles: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Dispositivos disponibles después de forzar CPU: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 19:43:35.075033: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-02-10 19:43:35.075109: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:137] retrieving CUDA diagnostic information for host: pc1\n",
      "2025-02-10 19:43:35.075127: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:144] hostname: pc1\n",
      "2025-02-10 19:43:35.075303: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:168] libcuda reported version is: 535.230.2\n",
      "2025-02-10 19:43:35.075363: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:172] kernel reported version is: 535.230.2\n",
      "2025-02-10 19:43:35.075377: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:259] kernel version seems to match DSO: 535.230.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Dropout, BatchNormalization, Input, Reshape, Lambda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "import os\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Verificar si realmente estamos en CPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Advertencia: ¡Todavía hay una GPU activa!\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles después de forzar CPU:\", tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una ventana oculta de Tkinter\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Create a hidden Tkinter window\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "\n",
    "# Initial path\n",
    "initial_path = Path(r'/home/felix/Escritorio/TFG/datasets_norm/goose_norm_test')\n",
    "\n",
    "\n",
    "try:\n",
    "    # Select the first path\n",
    "    print(\"Select the path for 'x_train'\")\n",
    "    x_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the second path\n",
    "    print(\"Select the path for 'y_train'\")\n",
    "    y_train_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_train'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the third path\n",
    "    print(\"Select the path for 'x_val'\")\n",
    "    x_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'x_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Select the fourth path\n",
    "    print(\"Select the path for 'y_val'\")\n",
    "    y_val_path = Path(filedialog.askdirectory(\n",
    "        title=\"Select the folder for 'y_val'\",\n",
    "        initialdir=initial_path\n",
    "    ))\n",
    "\n",
    "    # Show the selected paths\n",
    "    print(f\"Path selected for x_train: {x_train_path}\")\n",
    "    print(f\"Path selected for y_train: {y_train_path}\")\n",
    "    print(f\"Path selected for x_val: {x_val_path}\")\n",
    "    print(f\"Path selected for y_val: {y_val_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error selecting paths: {e}\")\n",
    "\n",
    "finally:\n",
    "    root.destroy()  # Ensure the Tkinter window is closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar y procesar los datos\n",
    "def load_data(x_path, y_path):\n",
    "    X_data, Y_data = [], []\n",
    "    num_points_list = []\n",
    "\n",
    "    for x_file in Path(x_path).iterdir():\n",
    "        if x_file.is_file() and x_file.suffix == '.csv':\n",
    "            y_file = Path(y_path) / x_file.name.replace('x_', 'y_')\n",
    "\n",
    "            x_df = pd.read_csv(x_file, header=None, skiprows=1)\n",
    "            y_df = pd.read_csv(y_file, header=None, skiprows=1)\n",
    "\n",
    "            x_features = x_df.iloc[:, [0, 1, 2]].astype(float).values\n",
    "            labels = y_df.iloc[:, 0].values\n",
    "\n",
    "            X_data.append(x_features)\n",
    "            Y_data.append(labels)\n",
    "            num_points_list.append(len(x_features))\n",
    "    \n",
    "    return X_data, Y_data, min(num_points_list)  # Retorna además el número mínimo de puntos\n",
    "\n",
    "# Cargar datos y obtener la cantidad mínima de puntos\n",
    "x_train, y_train, min_train_points = load_data(x_train_path, y_train_path)\n",
    "x_val, y_val, min_val_points = load_data(x_val_path, y_val_path)\n",
    "\n",
    "min_points = min(min_train_points, min_val_points)  # Definir la cantidad mínima global\n",
    "\n",
    "# def downsample_data(X_data, Y_data, num_points):\n",
    "#    X_downsampled, Y_downsampled = [], []\n",
    "#    for x, y in zip(X_data, Y_data):\n",
    "#        indices = np.random.permutation(len(x))[:num_points]  # Selección aleatoria\n",
    "#       X_downsampled.append(x[indices])\n",
    "#        Y_downsampled.append(y[indices])\n",
    "#    return np.array(X_downsampled), np.array(Y_downsampled)\n",
    "\n",
    "# Aplicar el downsampling\n",
    "#x_train, y_train = downsample_data(x_train, y_train, min_points)\n",
    "\n",
    "#x_val, y_val = downsample_data(x_val, y_val, min_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar las formas de los datos\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "num_features = 5  # XYZ + remission + otra característica\n",
    "num_classes = 64  # Número de clases a segmentar\n",
    "\n",
    "# Función T-Net para la transformación de características\n",
    "def tnet(inputs, k):\n",
    "    x = Conv1D(64, kernel_size=1, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(256, kernel_size=1, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(k * k, activation='linear', kernel_initializer='zeros')(x)\n",
    "    x = Reshape((k, k))(x)\n",
    "    return x\n",
    "\n",
    "# Entrada con tamaño variable\n",
    "inputs = Input(shape=(None, num_features))\n",
    "\n",
    "# Aplicar T-Net a la entrada\n",
    "tnet_transform = tnet(inputs, num_features)\n",
    "transformed_inputs = Lambda(lambda x: tf.linalg.matmul(x, tnet_transform))(inputs)\n",
    "\n",
    "# Bloque de extracción de características\n",
    "x = Conv1D(64, kernel_size=1, activation='relu')(transformed_inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(256, kernel_size=1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Aplicar T-Net en el espacio de características\n",
    "feature_tnet = tnet(x, 64)\n",
    "x = Lambda(lambda x: tf.linalg.matmul(x, feature_tnet))(x)\n",
    "\n",
    "# Expansión de características para segmentación punto a punto\n",
    "x = Conv1D(128, kernel_size=1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(64, kernel_size=1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Capa de salida con softmax para segmentación punto a punto\n",
    "outputs = Conv1D(num_classes, kernel_size=1, activation='softmax')(x)\n",
    "\n",
    "# Construcción del modelo funcional\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir métricas adicionales\n",
    "def mean_iou(y_true, y_pred):\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    return tf.keras.metrics.MeanIoU(num_classes=num_classes)(y_true, y_pred)\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), depth=num_classes)\n",
    "    y_pred = tf.one_hot(tf.argmax(y_pred, axis=-1), depth=num_classes)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2])\n",
    "    return tf.reduce_mean(2.0 * intersection / (union + 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', mean_iou, dice_coefficient])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
