{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pyntcloud import PyntCloud\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.pyplot as plt \n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "category_mapping_2 = {\n",
    "    0: [43, 38, 58, 29, 41, 42, 44, 39, 55],  # Construction\n",
    "    1: [4, 45, 6, 40, 60, 61, 33, 32, 14],  # Object\n",
    "    2: [7, 22, 9, 26, 11, 21],  # Road\n",
    "    3: [48, 47, 1, 19, 46, 10, 25],  # Sign\n",
    "    4: [23, 3, 24, 31, 2],  # Terrain\n",
    "    5: [51, 50, 5, 18],  # Drivable Vegetation\n",
    "    6: [28, 27, 62, 52, 16, 30, 59, 17],  # Non Drivable Vegetation\n",
    "    7: [13, 15, 12, 36, 57, 49, 20, 35, 37, 34, 63],  # Vehicle\n",
    "    8: [8, 56, 0, 53, 54],  # Void\n",
    "}\n",
    "\n",
    "# Generar el diccionario inverso para mapear etiquetas\n",
    "label_to_category = {label: cat for cat, labels in category_mapping_2.items() for label in labels}\n",
    "\n",
    "# Función para remapear etiquetas no válidas\n",
    "def map_labels(labels: np.ndarray) -> np.ndarray:\n",
    "    mapped = []\n",
    "    for label in labels:\n",
    "        if label in label_to_category:\n",
    "            mapped.append(label_to_category[label])\n",
    "        else:\n",
    "            print(f\"Etiqueta no mapeada encontrada: {label}\")\n",
    "            mapped.append(8)\n",
    "    return np.array(mapped, dtype=np.uint8)\n",
    "\n",
    "def load_bin_file(bin_path: str, num_points: int, radius: float = 25.0, seed: int = None):\n",
    "    full_points = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)\n",
    "    points = full_points[:, :3]\n",
    "    remission = full_points[:, 3]  # Añadir remission (shape: [N, 1])\n",
    "\n",
    "    distances = np.linalg.norm(points, axis=1)\n",
    "    mask = distances <= radius\n",
    "    points = points[mask]\n",
    "    remission = remission[mask]  # Filtrar remission también\n",
    "    num_available = points.shape[0]\n",
    "\n",
    "    if num_available >= num_points:\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)  # Establece semilla si se proporciona\n",
    "        indices = np.random.choice(num_available, num_points, replace=False)\n",
    "        return points[indices], remission[indices], np.where(mask)[0][indices]\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "def load_label_file(label_path: str, indices: np.ndarray) -> np.ndarray:\n",
    "    labels = np.fromfile(label_path, dtype=np.uint32) & 0xFFFF\n",
    "    return map_labels(labels[indices])\n",
    "\n",
    "def normalize_point_cloud(points):\n",
    "    mean = np.mean(points, axis=0)  # Media por dimensión\n",
    "    std = np.std(points, axis=0) + 1e-6  # Evitar divisiones por 0\n",
    "    return (points - mean) / std\n",
    "\n",
    "class GOOSEDataset(Dataset):\n",
    "    def __init__(self, x_path, y_path, num_points=4096, mode='train', batch_size=32):\n",
    "        self.x_files = sorted([os.path.join(x_path, f) for f in os.listdir(x_path) if f.endswith(\".bin\")])\n",
    "        self.y_files = sorted([os.path.join(y_path, f) for f in os.listdir(y_path) if f.endswith(\".label\")])\n",
    "        assert len(self.x_files) == len(self.y_files), \"Número de archivos de entrada y etiquetas no coinciden\"\n",
    "        self.num_points = num_points\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seed = 42 if self.mode == 'val' else None  # Semilla fija para validación\n",
    "        \n",
    "        points, remission, indices = load_bin_file(self.x_files[idx], self.num_points, radius=25.0, seed=seed)\n",
    "\n",
    "        if points is None or indices is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.x_files))\n",
    "        \n",
    "        labels = load_label_file(self.y_files[idx], indices)\n",
    "\n",
    "        if labels is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.x_files))\n",
    "\n",
    "        return torch.tensor(points, dtype=torch.float32), remission, torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point_sample(xyz, npoint):\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(xyz.device)\n",
    "    distance = torch.ones(B, N).to(xyz.device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(xyz.device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(xyz.device)\n",
    "\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].unsqueeze(1)  # (B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist\n",
    "\n",
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    B, N, _ = xyz.shape\n",
    "    _, S, _ = new_xyz.shape\n",
    "    group_idx = torch.arange(N, device=xyz.device).view(1, 1, N).repeat(B, S, 1)\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat(1, 1, nsample)\n",
    "    group_idx[group_idx == N] = group_first[group_idx == N]\n",
    "    return group_idx\n",
    "\n",
    "def sample_and_group(npoint, radius, nsample, xyz, points):\n",
    "    B, N, C = xyz.shape\n",
    "    fps_idx = farthest_point_sample(xyz, npoint)\n",
    "    new_xyz = index_points(xyz, fps_idx)\n",
    "\n",
    "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
    "    grouped_xyz = index_points(xyz, idx)  # [B, npoint, nsample, C]\n",
    "    grouped_xyz_norm = grouped_xyz - new_xyz.unsqueeze(2)\n",
    "\n",
    "    if points is not None:\n",
    "        grouped_points = index_points(points, idx)\n",
    "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1)\n",
    "    else:\n",
    "        new_points = grouped_xyz_norm\n",
    "\n",
    "    return new_xyz, new_points\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    points: (B, N, C)\n",
    "    idx: (B, S) o (B, S, K)\n",
    "    Return:\n",
    "        new_points: (B, S, C) o (B, S, K, C)\n",
    "    \"\"\"\n",
    "    B = points.shape[0]\n",
    "    batch_indices = torch.arange(B, device=points.device).view(B, 1, 1)\n",
    "\n",
    "    if idx.dim() == 2:\n",
    "        # idx: (B, S)\n",
    "        return points[torch.arange(B).view(-1, 1).to(points.device), idx]  # (B, S, C)\n",
    "    elif idx.dim() == 3:\n",
    "        # idx: (B, S, K)\n",
    "        batch_indices = batch_indices.expand(-1, idx.shape[1], idx.shape[2])\n",
    "        return points[batch_indices, idx]  # (B, S, K, C)\n",
    "    else:\n",
    "        raise ValueError(\"idx debe tener 2 o 3 dimensiones\")\n",
    "\n",
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
    "        super(PointNetSetAbstraction, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.group_all = group_all\n",
    "\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        xyz: (B, 3, N)\n",
    "        points: (B, D, N)\n",
    "        \"\"\"\n",
    "        B, C, N = xyz.shape\n",
    "\n",
    "        xyz = xyz.permute(0, 2, 1)  # [B, N, 3]\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1)  # [B, N, D]\n",
    "\n",
    "        if self.group_all:\n",
    "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
    "        else:\n",
    "            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
    "\n",
    "        # new_points: (B, npoint, nsample, C+D)\n",
    "        new_points = new_points.permute(0, 3, 2, 1)  # (B, C+D, nsample, npoint)\n",
    "\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "\n",
    "        new_points = torch.max(new_points, 2)[0]        # (B, mlp[-1], npoint)\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)              # (B, 3, npoint)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "class PointNetFeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        super(PointNetFeaturePropagation, self).__init__()\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz1, xyz2, points1, points2):\n",
    "        \"\"\"\n",
    "        xyz1: [B, 3, N] (target, upsampled)\n",
    "        xyz2: [B, 3, S] (source, sampled)\n",
    "        points1: [B, D1, N] (target features)\n",
    "        points2: [B, D2, S] (source features)\n",
    "        \"\"\"\n",
    "        B, C, N = xyz1.shape\n",
    "        _, _, S = xyz2.shape\n",
    "\n",
    "        if S == 1:\n",
    "            interpolated_points = points2.repeat(1, 1, N)\n",
    "        else:\n",
    "            dists = square_distance(xyz1.permute(0, 2, 1), xyz2.permute(0, 2, 1))  # (B, N, S)\n",
    "            dists, idx = dists.sort(dim=-1)\n",
    "            dists, idx = dists[:, :, :3], idx[:, :, :3]  # KNN: 3 vecinos\n",
    "\n",
    "            dist_recip = 1.0 / (dists + 1e-8)\n",
    "            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
    "            weight = dist_recip / norm\n",
    "\n",
    "            interpolated_points = torch.sum(index_points(points2.permute(0, 2, 1), idx) * weight.unsqueeze(-1), dim=2)\n",
    "            interpolated_points = interpolated_points.permute(0, 2, 1)\n",
    "\n",
    "        if points1 is not None:\n",
    "            new_points = torch.cat([points1, interpolated_points], dim=1)\n",
    "        else:\n",
    "            new_points = interpolated_points\n",
    "\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "\n",
    "        return new_points\n",
    "\n",
    "class PointNet2SemSeg(nn.Module):\n",
    "    def __init__(self, num_classes=3, normal_channel=False):\n",
    "        super(PointNet2SemSeg, self).__init__()\n",
    "        in_channel = 6 if normal_channel else 3\n",
    "\n",
    "        # Set Abstraction layers (encoder)\n",
    "        self.sa1 = PointNetSetAbstraction(npoint=1024, radius=1, nsample=32, in_channel=in_channel, mlp=[32, 32, 64], group_all=False)\n",
    "        self.sa2 = PointNetSetAbstraction(npoint=256, radius=3, nsample=64, in_channel=64 + 3, mlp=[64, 64, 128], group_all=False)\n",
    "        self.sa3 = PointNetSetAbstraction(npoint=64, radius=9, nsample=256, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)\n",
    "\n",
    "        # Feature Propagation layers (decoder)\n",
    "        self.fp3 = PointNetFeaturePropagation(in_channel=256 + 128, mlp=[256, 256])\n",
    "        self.fp2 = PointNetFeaturePropagation(in_channel=256 + 64, mlp=[256, 128])\n",
    "        self.fp1 = PointNetFeaturePropagation(in_channel=128, mlp=[128, 128, 128])\n",
    "\n",
    "        # MLP for segmentation\n",
    "        self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 3, N)\n",
    "        B, _, N = x.shape\n",
    "        l0_xyz = x\n",
    "        l0_points = None  # Optional: pass features here (e.g., normals)\n",
    "\n",
    "        # Encoder\n",
    "        l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "\n",
    "        # Decoder (Feature Propagation)\n",
    "        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)\n",
    "        l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)\n",
    "        l0_points = self.fp1(l0_xyz, l1_xyz, l0_points, l1_points)\n",
    "\n",
    "        # Output segmentation scores per point\n",
    "        x = F.relu(self.bn1(self.conv1(l0_points)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)  # (B, num_classes, N)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Modelo y Evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# Paso 1: Instanciar tu modelo\n",
    "model = PointNet2SemSeg(num_classes=9)\n",
    "\n",
    "# Paso 2: Cargar el state_dict en CPU\n",
    "state_dict = torch.load(\n",
    "    \"/Users/felixmaral/Desktop/TFG/2024-tfg-felix-martinez/segmentation/deep_learning/results/pointnet++_no_rem_v0/pointnet2_no_remission_v0.pth\",\n",
    "    map_location=DEVICE\n",
    ")\n",
    "\n",
    "# Paso 3: Cargar pesos\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Paso 4: Mover a dispositivo y poner en modo evaluación\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = \"/home/fmartinez/datasets/goose/lidar/train\"\n",
    "y_train_path = \"/home/fmartinez/datasets/goose/labels/train\"\n",
    "x_val_path = \"/home/fmartinez/datasets/goose/lidar/val\"\n",
    "y_val_path = \"/home/fmartinez/datasets/goose/labels/val\"\n",
    "x_test_path = \"/Users/felixmaral/Downloads/Rellis-3D/00001/vel_cloud_node_kitti_bin\"\n",
    "y_test_path = \"/Users/felixmaral/Downloads/Rellis-3D_2/00001/vel_cloud_node_semantickitti_label_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset y DataLoader\n",
    "NUM_TEST_POINTS = 16384\n",
    "\n",
    "test_dataset = GOOSEDataset(\n",
    "    x_path=x_test_path, \n",
    "    y_path=y_test_path, \n",
    "    num_points=NUM_TEST_POINTS, \n",
    "    mode=\"val\"\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "all_points = []\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (points, remission, labels) in enumerate(tqdm(test_loader, desc=\"Inferencia\", unit=\"batch\")):\n",
    "        all_points.append(points.numpy())  # (B, N, 3)\n",
    "\n",
    "        # Preparar inputs\n",
    "        points_t = points.permute(0, 2, 1).to(DEVICE)  # (B, 3, N)\n",
    "\n",
    "        # Ajustar remission si es necesario\n",
    "        if remission.ndim == 2:\n",
    "            remission = remission.unsqueeze(1)  # (B, 1, N)\n",
    "        remission_t = remission.to(DEVICE)\n",
    "\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Inferencia\n",
    "        pred = model(points_t)  # (B, num_classes, N)\n",
    "        pred_classes = pred.argmax(dim=1)\n",
    "\n",
    "        all_preds.append(pred_classes.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenar todo\n",
    "all_points = np.concatenate(all_points, axis=0)   # (num_samples, N, 3)\n",
    "all_labels = np.concatenate(all_labels, axis=0)   # (num_samples, N)\n",
    "all_preds = np.concatenate(all_preds, axis=0)     # (num_samples, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define color map for 3 categories\n",
    "color_map = {\n",
    "    0: \"gray\",        # Construcción\n",
    "    1: \"orange\",      # Objeto\n",
    "    2: \"blue\",        # Carretera\n",
    "    3: \"red\",         # Señales\n",
    "    4: \"brown\",       # Terreno\n",
    "    5: \"lightgreen\",  # Vegetación transitable\n",
    "    6: \"darkgreen\",   # Vegetación no transitable\n",
    "    7: \"yellow\",      # Vehículo\n",
    "    8: \"black\"        # Vacío\n",
    "}\n",
    "\n",
    "# Function to plot the confusion matrix in percentage\n",
    "def plot_confusion_matrix_percentage(y_val, predicted_labels, num_classes=9):\n",
    "    y_true = y_val.flatten()\n",
    "    y_pred = predicted_labels.flatten()\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "    \n",
    "    # Convert to percentage\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1, keepdims=True) * 100\n",
    "    cm_percentage = np.nan_to_num(cm_percentage)  # Avoid NaNs due to division by zero\n",
    "\n",
    "    class_labels = {\n",
    "        0: \"Construction\",  # Gris\n",
    "        1: \"Object\",  # Naranja\n",
    "        2: \"Road\",  # Azul\n",
    "        3: \"Sign\",  # Rojo\n",
    "        4: \"Terrain\",  # Marrón\n",
    "        5: \"Drivable Vegetation\",  # Verde claro\n",
    "        6: \"Non Drivable Vegetation\",  # Verde oscuro\n",
    "        7: \"Vehicle\",  # Amarillo\n",
    "        8: \"Void\"  # Negro\n",
    "    }\n",
    "    \n",
    "    class_names = [class_labels[i] for i in range(num_classes)]\n",
    "\n",
    "    unique_classes, counts = np.unique(y_val.flatten(), return_counts=True)\n",
    "    print(\"Distribución de clases reales:\")\n",
    "    for cls, count in zip(unique_classes, counts):\n",
    "        print(f\"Clase {cls}: {count} puntos\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_percentage, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names,\n",
    "                vmin=0, vmax=100)\n",
    "\n",
    "    plt.xlabel(\"Predicted Classes\")\n",
    "    plt.ylabel(\"Ground Truth Classes\")\n",
    "    plt.title(\"Confusion Matrix - PointNet++ (RELLIS-3D test)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "color_mapping_2 = {\n",
    "    0: \"gray\",        # Construcción\n",
    "    1: \"orange\",      # Objeto\n",
    "    2: \"blue\",        # Carretera\n",
    "    3: \"red\",         # Señales\n",
    "    4: \"brown\",       # Terreno\n",
    "    5: \"lightgreen\",  # Vegetación transitable\n",
    "    6: \"darkgreen\",   # Vegetación no transitable\n",
    "    7: \"yellow\",      # Vehículo\n",
    "    8: \"black\"        # Vacío\n",
    "}\n",
    "\n",
    "class_labels_2 = {\n",
    "    0: \"Construction\",  # Gris\n",
    "    1: \"Object\",  # Naranja\n",
    "    2: \"Road\",  # Azul\n",
    "    3: \"Sign\",  # Rojo\n",
    "    4: \"Terrain\",  # Marrón\n",
    "    5: \"Drivable Vegetation\",  # Verde claro\n",
    "    6: \"Non Drivable Vegetation\",  # Verde oscuro\n",
    "    7: \"Vehicle\",  # Amarillo\n",
    "    8: \"Void\"  # Negro\n",
    "}\n",
    "\n",
    "def visualizar_comparacion_segmentacion(x_val, y_val, predicted_labels, indice):\n",
    "    if indice >= len(x_val):\n",
    "        print(f\"Índice fuera de rango. Debe estar entre 0 y {len(x_val)-1}.\")\n",
    "        return\n",
    "\n",
    "    puntos = x_val[indice]\n",
    "    etiquetas_reales = y_val[indice]\n",
    "    etiquetas_predichas = predicted_labels[indice]\n",
    "\n",
    "    fig_real = go.Figure()\n",
    "    fig_pred = go.Figure()\n",
    "\n",
    "    for class_id, class_name in class_labels_2.items():\n",
    "        indices_real = np.where(etiquetas_reales == class_id)[0]\n",
    "        indices_pred = np.where(etiquetas_predichas == class_id)[0]\n",
    "\n",
    "        if len(indices_real) > 0:\n",
    "            fig_real.add_trace(go.Scatter3d(\n",
    "                x=puntos[indices_real, 0],\n",
    "                y=puntos[indices_real, 1],\n",
    "                z=puntos[indices_real, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=1.5,\n",
    "                    color=color_mapping_2[class_id],\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f\"[Real] {class_name}\",\n",
    "                showlegend=False  # Ocultamos la leyenda real para sustituirla por trazas personalizadas\n",
    "            ))\n",
    "\n",
    "        if len(indices_pred) > 0:\n",
    "            fig_pred.add_trace(go.Scatter3d(\n",
    "                x=puntos[indices_pred, 0],\n",
    "                y=puntos[indices_pred, 1],\n",
    "                z=puntos[indices_pred, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=1.5,\n",
    "                    color=color_mapping_2[class_id],\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name=f\"[Predicho] {class_name}\",\n",
    "                showlegend=False  # Lo mismo aquí\n",
    "            ))\n",
    "\n",
    "    # Añadir una traza vacía por clase para la leyenda con tamaño grande\n",
    "    for class_id, class_name in class_labels_2.items():\n",
    "        fig_real.add_trace(go.Scatter(\n",
    "            x=[None], y=[None], mode='markers',\n",
    "            marker=dict(size=10, color=color_mapping_2[class_id]),\n",
    "            name=f\"[Real] {class_name}\",\n",
    "            showlegend=True\n",
    "        ))\n",
    "        fig_pred.add_trace(go.Scatter(\n",
    "            x=[None], y=[None], mode='markers',\n",
    "            marker=dict(size=10, color=color_mapping_2[class_id]),\n",
    "            name=f\"[Predicho] {class_name}\",\n",
    "            showlegend=True\n",
    "        ))\n",
    "\n",
    "    # Layouts\n",
    "    fig_real.update_layout(\n",
    "        title=f\"Segmentación Real - Índice {indice}\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        legend_title=\"Clases de Segmentación\",\n",
    "        legend=dict(font=dict(size=14))\n",
    "    )\n",
    "\n",
    "    fig_pred.update_layout(\n",
    "        title=f\"Segmentación Predicha - Índice {indice}\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        legend_title=\"Clases de Segmentación\",\n",
    "        legend=dict(font=dict(size=14))\n",
    "    )\n",
    "\n",
    "    fig_real.show()\n",
    "    fig_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "def visualizar_prediccion_matplotlib(points_array, predicted_labels_array, indice, color_map, class_labels):\n",
    "    \"\"\"\n",
    "    Visualiza toda la nube de puntos coloreada por etiqueta predicha.\n",
    "    \"\"\"\n",
    "    if indice >= len(points_array):\n",
    "        print(f\"Índice fuera de rango. Debe estar entre 0 y {len(points_array)-1}.\")\n",
    "        return\n",
    "\n",
    "    points = points_array[indice]            # (N,3)\n",
    "    pred_labels = predicted_labels_array[indice]  # (N,)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "    # Colores por punto\n",
    "    colors = [color_map.get(label, \"black\") for label in pred_labels]\n",
    "\n",
    "    # Scatter completo\n",
    "    ax.scatter(\n",
    "        points[:,0], points[:,1], points[:,2],\n",
    "        s=1.5,\n",
    "        c=colors,\n",
    "        alpha=1.0\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"PointNet++*\", fontsize=14)\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Leyenda\n",
    "    unique_labels = np.unique(pred_labels)\n",
    "    legend_elements = []\n",
    "    for label in unique_labels:\n",
    "        legend_elements.append(\n",
    "            plt.Line2D(\n",
    "                [0], [0],\n",
    "                marker='o',\n",
    "                color='w',\n",
    "                label=class_labels.get(label, str(label)),\n",
    "                markerfacecolor=color_map.get(label, \"black\"),\n",
    "                markersize=6\n",
    "            )\n",
    "        )\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc=\"upper right\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels[167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suponiendo que all_labels[167] es un array de etiquetas\n",
    "labels_167 = all_labels[167]\n",
    "\n",
    "values, counts = np.unique(labels_167, return_counts=True)\n",
    "\n",
    "# Mostrar los resultados\n",
    "for v, c in zip(values, counts):\n",
    "    print(f\"Etiqueta {v}: {c} ocurrencias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizar_comparacion_segmentacion(all_points, all_labels, all_preds, indice=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizar_prediccion_matplotlib(all_points, all_preds, indice=200, color_map=color_mapping_2, class_labels=class_labels_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_percentage(all_labels, all_preds, num_classes=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flatten para comparar punto a punto\n",
    "all_preds = all_preds.flatten()\n",
    "all_labels = all_labels.flatten()\n",
    "\n",
    "accuracy = np.mean(all_preds == all_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# all_labels: etiquetas reales (1D array)\n",
    "# all_preds: etiquetas predichas (1D array)\n",
    "num_classes = np.max(all_labels) + 1  # O usa un valor fijo si lo prefieres\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "\n",
    "# Intersección y unión para IoU\n",
    "intersection = np.diag(conf_matrix)\n",
    "union = conf_matrix.sum(axis=1) + conf_matrix.sum(axis=0) - intersection\n",
    "iou_per_class = intersection / np.maximum(union, 1e-6)\n",
    "miou = np.mean(iou_per_class)\n",
    "\n",
    "# Accuracy global\n",
    "total_correct = np.trace(conf_matrix)\n",
    "total_points = np.sum(conf_matrix)\n",
    "overall_accuracy = total_correct / total_points\n",
    "\n",
    "# Accuracy por clase (recall por clase)\n",
    "class_accuracy = intersection / np.maximum(conf_matrix.sum(axis=1), 1e-6)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Global Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "print(f\"Mean IoU: {miou * 100:.2f}%\\n\")\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print(f\"Class {i} - IoU: {iou_per_class[i] * 100:.2f}%, Accuracy: {class_accuracy[i] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
