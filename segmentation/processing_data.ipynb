{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de implementación de PoinNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este _notebook_ está dedicado a probar una **implementación de PointNet con Tensorflow 2.0 y Keras**. Se utilizará un subconjunto de validación del **GOOSE dataset** para entrenar el modelo. Este consta de **151 nubes de puntos** de una dimensión variable. Se realizará un estudio estadístico de las clases contenidas en estas 151 nubes de puntos para evaluar si es necesario completar con más nubes de puntos que contengan las clases faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del GOOSE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "\n",
    "# point_clouds_path = Path(r\"goose\\val\\2022-07-22_flight\")\n",
    "# labels_path = Path(r\"goose\\labels\\val\\2022-07-22_flight\")\n",
    "\n",
    "# Linux\n",
    "\n",
    "point_clouds_path = Path(r\"/home/felix/Escritorio/TFG/datasets/Goose/goose_3d_val/lidar/val/2022-07-22_flight\")\n",
    "labels_path = Path(r\"/home/felix/Escritorio/TFG/datasets/Goose/goose_3d_val/labels/val/2022-07-22_flight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ordenan los archivos para establecer un orden entre nubes de puntos y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = os.listdir(point_clouds_path)\n",
    "labels_list = os.listdir(labels_path)\n",
    "\n",
    "sorted_files = sorted(files_list, key=lambda x: int(re.search(r'__\\d{4,5}_', x).group(0)[2:-1]))\n",
    "sorted_labels = sorted(labels_list, key=lambda x: int(re.search(r'__\\d{4,5}_', x).group(0)[2:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de caracteristicas del Dataset Bruto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción del minimo y el máximo de numero de puntos en las 151 muestras LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_len_point_clouds = []\n",
    "\n",
    "# Reading .bin files and adding to DF\n",
    "for file in os.listdir(point_clouds_path):\n",
    "    scan = np.fromfile(os.path.join(point_clouds_path, file), dtype=np.float32)\n",
    "    scan = scan.reshape((-1, 4))\n",
    "\n",
    "    # put in attribute\n",
    "    points = scan[:, 0:3]    # get xyz\n",
    "    remissions = scan[:, 3]  # get remission\n",
    "\n",
    "    list_len_point_clouds.append(len(points))\n",
    "\n",
    "list_len_point_clouds = np.array(list_len_point_clouds)\n",
    "\n",
    "min_idx = list_len_point_clouds.argmin() \n",
    "max_idx = list_len_point_clouds.argmax()\n",
    "\n",
    "min = list_len_point_clouds[min_idx]\n",
    "max = list_len_point_clouds[max_idx]\n",
    "\n",
    "print(f\"La nube con más puntos tiene: {max}\")\n",
    "print(f\"La nube con menos puntos tiene: {min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de las clases existentes y su numero de puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = []\n",
    "\n",
    "\n",
    "for file in os.listdir(labels_path):\n",
    "\n",
    "    # reading a .label file\n",
    "    label = np.fromfile(os.path.join(labels_path, file), dtype=np.uint32)\n",
    "    label = label.reshape((-1))\n",
    "\n",
    "    # extract the semantic and instance label IDs\n",
    "    sem_label = label & 0xFFFF  # semantic label in lower half\n",
    "\n",
    "    list_labels.append(pd.DataFrame(sem_label, columns=[\"sem_label\"]))\n",
    "\n",
    "df_list_labels = pd.concat(list_labels)\n",
    "    \n",
    "# df_list_labels\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.hist(df_list_labels['sem_label'], \n",
    "         bins=np.arange(df_list_labels['sem_label'].min(), df_list_labels['sem_label'].max() + 2), \n",
    "         edgecolor='k', \n",
    "         alpha=0.7)\n",
    "\n",
    "# Personalización del gráfico\n",
    "plt.title(\"Histograma de Etiquetas Semánticas\")\n",
    "plt.xlabel(\"Etiqueta Semántica\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Configurar las marcas del eje X en incrementos de 5\n",
    "x_ticks = np.arange(df_list_labels['sem_label'].min(), df_list_labels['sem_label'].max() + 1, 5)\n",
    "plt.xticks(x_ticks)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora guardamos en un diccionario la **frecuencia** de cada clase semántica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_freq_classes = df_list_labels['sem_label'].value_counts().sort_index().to_dict()\n",
    "\n",
    "print(dict_freq_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del Dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se leen los puntos de cada muestra y las etiquetas de cada muestra. `list_point_clouds` **es una lista** que almacena las 151 nubes de puntos, cada una es un dataframe con las columnas `x`, `y`, `z`, `remissions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_point_clouds = []\n",
    "\n",
    "# Reading .bin files and adding to DF\n",
    "for file in os.listdir(point_clouds_path):\n",
    "    scan = np.fromfile(os.path.join(point_clouds_path, file), dtype=np.float32)\n",
    "    scan = scan.reshape((-1, 4))\n",
    "\n",
    "    # put in attribute\n",
    "    points = scan[:, 0:3]    # get xyz\n",
    "    remissions = scan[:, 3]  # get remission\n",
    "\n",
    "    df_point_cloud = pd.DataFrame(points, columns=[\"x\",\"y\",\"z\"])\n",
    "    df_point_cloud[\"remissions\"] = remissions\n",
    "    list_point_clouds.append(df_point_cloud)\n",
    "\n",
    "# print(list_point_clouds[0:2])\n",
    "# print(list_labels[0:2])\n",
    "\n",
    "del df_point_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda se imprime por pantalla ***el DataFrame*** que representa la nube de puntos **nº40**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_point_clouds[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar que la normalización se contamine del ruido que pueden contener algunos valores de la nube de puntos se realiza una **normalización de media 0 y varianza 1** para las `remisiones` y una normalización que redimensione la nube de puntos a una esfera unitaria para las entradas geométricas `x`, `y` y `z` \n",
    "\n",
    "En primer lugar dividimos nuestro conjunto en subconjuntos de entrenamiento y validación\n",
    "- Se normalizan ambos subconjuntos en función a esos estadísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 120 nubes de puntos en el conjunto de entrenamiento\n",
      "Hay 31 nubes de puntos en el conjunto de validación\n"
     ]
    }
   ],
   "source": [
    "# División: train, val\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(list_point_clouds, list_labels, test_size=0.2, random_state=42) # random_state para estabilidad en los experimentos\n",
    "\n",
    "print(f'Hay {len(x_train)} nubes de puntos en el conjunto de entrenamiento')\n",
    "print(f'Hay {len(x_val)} nubes de puntos en el conjunto de validación')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calculan los estadísticos de las remisiones del conjunto de entrenamiento y l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las media de las remisiones son: \n",
      "\n",
      "29.32798194885254\n",
      "\n",
      "Las desviación estandar de las remisiones son: \n",
      "\n",
      "20.90127944946289\n"
     ]
    }
   ],
   "source": [
    "# Cálculo de los estadísticos de x_train\n",
    "\n",
    "x_train_concat = pd.concat(x_train)\n",
    "\n",
    "mean = x_train_concat[\"remissions\"].mean()\n",
    "std = x_train_concat[\"remissions\"].std()\n",
    "\n",
    "print(f'Las media de las remisiones son: \\n\\n{means}\\n')\n",
    "print(f'Las desviación estandar de las remisiones son: \\n\\n{stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.732\n",
      "113.732\n"
     ]
    }
   ],
   "source": [
    "# Eliminar outliers usando percentiles\n",
    "\n",
    "x_train_concat['distance'] = np.sqrt(x_train_concat['x']**2 + x_train_concat['y']**2 + x_train_concat['z']**2)\n",
    "\n",
    "# 2. Calcular el percentil deseado (por ejemplo, 99%)\n",
    "threshold = np.percentile(x_train_concat['distance'], 97)\n",
    "\n",
    "print(threshold)\n",
    "\n",
    "x_train_concat_filtered = x_train_concat[x_train_concat['distance'] <= threshold].copy()\n",
    "\n",
    "d_max = np.sqrt(x_train_concat_filtered['x']**2 + x_train_concat_filtered['y']**2 + x_train_concat_filtered['z']**2).max()\n",
    "\n",
    "print(d_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>remissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.010641</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.004994</td>\n",
       "      <td>-0.398444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054726</td>\n",
       "      <td>-0.006168</td>\n",
       "      <td>-0.019591</td>\n",
       "      <td>-1.259635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.068293</td>\n",
       "      <td>-0.007624</td>\n",
       "      <td>-0.019759</td>\n",
       "      <td>-0.398444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.082959</td>\n",
       "      <td>-0.008778</td>\n",
       "      <td>-0.020128</td>\n",
       "      <td>-0.494132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.096179</td>\n",
       "      <td>-0.011503</td>\n",
       "      <td>-0.020134</td>\n",
       "      <td>-0.541975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181216</th>\n",
       "      <td>-0.436390</td>\n",
       "      <td>-0.051882</td>\n",
       "      <td>0.044096</td>\n",
       "      <td>0.127840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181217</th>\n",
       "      <td>-0.429196</td>\n",
       "      <td>-0.050495</td>\n",
       "      <td>0.046032</td>\n",
       "      <td>-0.685507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181218</th>\n",
       "      <td>-0.448852</td>\n",
       "      <td>-0.052252</td>\n",
       "      <td>0.051326</td>\n",
       "      <td>-0.015692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181219</th>\n",
       "      <td>-0.438318</td>\n",
       "      <td>-0.050560</td>\n",
       "      <td>0.054019</td>\n",
       "      <td>-0.541975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181220</th>\n",
       "      <td>-0.443145</td>\n",
       "      <td>-0.050412</td>\n",
       "      <td>0.059351</td>\n",
       "      <td>0.319216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181221 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x         y         z  remissions\n",
       "0      -0.010641 -0.001212 -0.004994   -0.398444\n",
       "1      -0.054726 -0.006168 -0.019591   -1.259635\n",
       "2      -0.068293 -0.007624 -0.019759   -0.398444\n",
       "3      -0.082959 -0.008778 -0.020128   -0.494132\n",
       "4      -0.096179 -0.011503 -0.020134   -0.541975\n",
       "...          ...       ...       ...         ...\n",
       "181216 -0.436390 -0.051882  0.044096    0.127840\n",
       "181217 -0.429196 -0.050495  0.046032   -0.685507\n",
       "181218 -0.448852 -0.052252  0.051326   -0.015692\n",
       "181219 -0.438318 -0.050560  0.054019   -0.541975\n",
       "181220 -0.443145 -0.050412  0.059351    0.319216\n",
       "\n",
       "[181221 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_list_point_clouds = []\n",
    "\n",
    "for df in list_point_clouds:\n",
    "    norm_df = df.copy()\n",
    "    norm_df[['x','y','z']] = (df[['x','y','z']] / d_max)\n",
    "    norm_df['remissions'] = (norm_df['remissions'] - mean) / std\n",
    "    norm_list_point_clouds.append(norm_df)\n",
    "\n",
    "norm_list_point_clouds[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se guardan en archivos csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ./data/goose_norm_files/dataframe_0.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_1.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_2.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_3.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_4.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_5.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_6.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_7.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_8.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_9.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_10.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_11.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_12.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_13.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_14.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_15.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_16.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_17.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_18.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_19.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_20.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_21.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_22.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_23.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_24.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_25.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_26.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_27.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_28.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_29.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_30.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_31.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_32.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_33.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_34.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_35.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_36.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_37.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_38.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_39.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_40.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_41.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_42.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_43.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_44.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_45.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_46.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_47.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_48.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_49.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_50.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_51.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_52.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_53.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_54.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_55.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_56.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_57.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_58.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_59.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_60.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_61.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_62.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_63.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_64.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_65.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_66.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_67.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_68.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_69.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_70.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_71.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_72.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_73.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_74.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_75.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_76.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_77.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_78.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_79.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_80.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_81.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_82.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_83.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_84.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_85.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_86.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_87.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_88.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_89.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_90.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_91.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_92.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_93.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_94.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_95.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_96.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_97.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_98.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_99.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_100.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_101.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_102.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_103.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_104.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_105.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_106.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_107.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_108.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_109.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_110.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_111.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_112.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_113.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_114.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_115.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_116.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_117.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_118.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_119.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_120.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_121.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_122.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_123.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_124.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_125.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_126.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_127.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_128.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_129.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_130.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_131.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_132.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_133.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_134.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_135.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_136.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_137.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_138.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_139.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_140.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_141.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_142.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_143.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_144.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_145.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_146.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_147.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_148.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_149.csv\n",
      "Guardado: ./data/goose_norm_files/dataframe_150.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/home/felix/Escritorio/TFG/datasets_norm/goose_norm_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Guardar cada DataFrame en un archivo\n",
    "for i, df in enumerate(norm_list_point_clouds):\n",
    "    # Define el nombre del archivo, por ejemplo: dataframe_0.csv\n",
    "    file_name = f\"dataframe_{i}.csv\"  # Cambia a .parquet si prefieres parquet\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    # Guardar el DataFrame como CSV\n",
    "    df.to_csv(file_path, index=False)  # Usa index=False para omitir el índice\n",
    "    print(f\"Guardado: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
